{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automatic Answering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQd0OJpYCHgt",
        "outputId": "839bef86-cb79-4e8a-be72-2f7c5bef12fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzRA-DIEEj8Y"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.read_excel('/content/drive/My Drive/train.xlsx')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "XGZbeRFihbHQ",
        "outputId": "4fff42df-a384-4050-c140-dcacd4d83e95"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sl.no</th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What do you understand by Natural Language Pro...</td>\n",
              "      <td>Natural Language Processing is a field of comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>What are stop words?</td>\n",
              "      <td>Stop words are said to be useless data for a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>List any two real-life applications of Natural...</td>\n",
              "      <td>Google Translate, Chatbots</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>What is TF-IDF?</td>\n",
              "      <td>TFIDF or Term Frequency-Inverse Document Frequ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>What is Syntactic Analysis?</td>\n",
              "      <td>Syntactic Analysis is a technique of analyzing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sl.no  ...                                            Answers\n",
              "0      1  ...  Natural Language Processing is a field of comp...\n",
              "1      2  ...  Stop words are said to be useless data for a s...\n",
              "2      3  ...                         Google Translate, Chatbots\n",
              "3      4  ...  TFIDF or Term Frequency-Inverse Document Frequ...\n",
              "4      5  ...  Syntactic Analysis is a technique of analyzing...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj1P-pAB1f0i",
        "outputId": "da87ce88-73eb-4994-a972-8a330cbfa595"
      },
      "source": [
        "import re\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "\n",
        "#from nltk.stem.lancaster import LancasterStemmer\n",
        "\n",
        "def clean_sentence(sentence, stopwords=False):\n",
        "\n",
        "  sentence = sentence.lower().strip()\n",
        "  sentence = re.sub(r'[^a-z0-9\\s]', '', sentence)\n",
        "\n",
        "  if stopwords:\n",
        "    sentence = remove_stopwords(sentence)\n",
        "  return sentence\n",
        "\n",
        "def get_cleaned_sentences(df,stopwords=False):\n",
        "  sents=df[[\"Questions\"]]\n",
        "  cleaned_sentences=[]\n",
        "\n",
        "  for index,row in df.iterrows():\n",
        "    #print(index,row)\n",
        "    cleaned=clean_sentence(row[\"Questions\"],stopwords);\n",
        "    cleaned_sentences.append(cleaned);\n",
        "  return cleaned_sentences;\n",
        "\n",
        "cleaned_sentences=get_cleaned_sentences(df,stopwords=True)\n",
        "print(cleaned_sentences);\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "cleaned_sentences_with_stopwords=get_cleaned_sentences(df,stopwords=False)\n",
        "print(cleaned_sentences_with_stopwords);"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['understand natural language processing', 'stop words', 'list reallife applications natural language processing', 'tfidf', 'syntactic analysis', 'semantic analysis', 'nltk', 'tokenize sentence nltk package', 'explain parsing', 'explain stemming', 'pragmatic analysis', 'pragmatic ambiguity', 'unigrams bigrams trigrams ngrams nlp', 'feature extraction nlp', 'partsofspeech tagging', 'explain named entity recognition', 'nlp process removing words like sentence called', 'tfidf helps establish', 'nlp process identifying people organization given sentence paragraph called', 'explain briefly word2vec']\n",
            "\n",
            "\n",
            "['what do you understand by natural language processing', 'what are stop words', 'list any two reallife applications of natural language processing', 'what is tfidf', 'what is syntactic analysis', 'what is semantic analysis', 'what is nltk', 'how to tokenize a sentence using the nltk package', 'explain how we can do parsing', 'explain stemming', 'what is pragmatic analysis', 'what is pragmatic ambiguity', 'what are unigrams bigrams trigrams and ngrams in nlp', 'what is feature extraction in nlp', 'what is partsofspeech tagging', 'explain named entity recognition', 'in nlp the process of removing words like and is a an the from a sentence is called as', 'tfidf helps you to establish', 'in nlp the process of identifying people an organization from a given sentence paragraph is called', 'explain briefly about word2vec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1kVA_0A-qaq"
      },
      "source": [
        "Bag of words Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TjI75zV-29h",
        "outputId": "6b5ee4b0-824f-490e-e84c-c21bf5a81f2b"
      },
      "source": [
        "import numpy\n",
        "\n",
        "sentences=cleaned_sentences_with_stopwords\n",
        "\n",
        "#split it by white space\n",
        "sentence_words = [[word for word in document.split() ]\n",
        "                  for document in sentences]\n",
        "\n",
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(sentence_words)\n",
        "for key, value in dictionary.items():\n",
        "    print(key,' : ', value)\n",
        "import pprint\n",
        "bow_corpus = [dictionary.doc2bow(text) for text in sentence_words]\n",
        "\n",
        "for sent,embedding in zip(sentences,bow_corpus):\n",
        "    print(sent)\n",
        "    print(embedding)\n",
        "question_orig=\"What are the applications of NLP?\"\n",
        "question=clean_sentence(question_orig,stopwords=False);\n",
        "question_embedding = dictionary.doc2bow(question.split())\n",
        "\n",
        "print(\"\\n\\n\",question,\"\\n\",question_embedding)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  :  by\n",
            "1  :  do\n",
            "2  :  language\n",
            "3  :  natural\n",
            "4  :  processing\n",
            "5  :  understand\n",
            "6  :  what\n",
            "7  :  you\n",
            "8  :  are\n",
            "9  :  stop\n",
            "10  :  words\n",
            "11  :  any\n",
            "12  :  applications\n",
            "13  :  list\n",
            "14  :  of\n",
            "15  :  reallife\n",
            "16  :  two\n",
            "17  :  is\n",
            "18  :  tfidf\n",
            "19  :  analysis\n",
            "20  :  syntactic\n",
            "21  :  semantic\n",
            "22  :  nltk\n",
            "23  :  a\n",
            "24  :  how\n",
            "25  :  package\n",
            "26  :  sentence\n",
            "27  :  the\n",
            "28  :  to\n",
            "29  :  tokenize\n",
            "30  :  using\n",
            "31  :  can\n",
            "32  :  explain\n",
            "33  :  parsing\n",
            "34  :  we\n",
            "35  :  stemming\n",
            "36  :  pragmatic\n",
            "37  :  ambiguity\n",
            "38  :  and\n",
            "39  :  bigrams\n",
            "40  :  in\n",
            "41  :  ngrams\n",
            "42  :  nlp\n",
            "43  :  trigrams\n",
            "44  :  unigrams\n",
            "45  :  extraction\n",
            "46  :  feature\n",
            "47  :  partsofspeech\n",
            "48  :  tagging\n",
            "49  :  entity\n",
            "50  :  named\n",
            "51  :  recognition\n",
            "52  :  an\n",
            "53  :  as\n",
            "54  :  called\n",
            "55  :  from\n",
            "56  :  like\n",
            "57  :  process\n",
            "58  :  removing\n",
            "59  :  establish\n",
            "60  :  helps\n",
            "61  :  given\n",
            "62  :  identifying\n",
            "63  :  organization\n",
            "64  :  paragraph\n",
            "65  :  people\n",
            "66  :  about\n",
            "67  :  briefly\n",
            "68  :  word2vec\n",
            "what do you understand by natural language processing\n",
            "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
            "what are stop words\n",
            "[(6, 1), (8, 1), (9, 1), (10, 1)]\n",
            "list any two reallife applications of natural language processing\n",
            "[(2, 1), (3, 1), (4, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1)]\n",
            "what is tfidf\n",
            "[(6, 1), (17, 1), (18, 1)]\n",
            "what is syntactic analysis\n",
            "[(6, 1), (17, 1), (19, 1), (20, 1)]\n",
            "what is semantic analysis\n",
            "[(6, 1), (17, 1), (19, 1), (21, 1)]\n",
            "what is nltk\n",
            "[(6, 1), (17, 1), (22, 1)]\n",
            "how to tokenize a sentence using the nltk package\n",
            "[(22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]\n",
            "explain how we can do parsing\n",
            "[(1, 1), (24, 1), (31, 1), (32, 1), (33, 1), (34, 1)]\n",
            "explain stemming\n",
            "[(32, 1), (35, 1)]\n",
            "what is pragmatic analysis\n",
            "[(6, 1), (17, 1), (19, 1), (36, 1)]\n",
            "what is pragmatic ambiguity\n",
            "[(6, 1), (17, 1), (36, 1), (37, 1)]\n",
            "what are unigrams bigrams trigrams and ngrams in nlp\n",
            "[(6, 1), (8, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1)]\n",
            "what is feature extraction in nlp\n",
            "[(6, 1), (17, 1), (40, 1), (42, 1), (45, 1), (46, 1)]\n",
            "what is partsofspeech tagging\n",
            "[(6, 1), (17, 1), (47, 1), (48, 1)]\n",
            "explain named entity recognition\n",
            "[(32, 1), (49, 1), (50, 1), (51, 1)]\n",
            "in nlp the process of removing words like and is a an the from a sentence is called as\n",
            "[(10, 1), (14, 1), (17, 2), (23, 2), (26, 1), (27, 2), (38, 1), (40, 1), (42, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1)]\n",
            "tfidf helps you to establish\n",
            "[(7, 1), (18, 1), (28, 1), (59, 1), (60, 1)]\n",
            "in nlp the process of identifying people an organization from a given sentence paragraph is called\n",
            "[(14, 1), (17, 1), (23, 1), (26, 1), (27, 1), (40, 1), (42, 1), (52, 1), (54, 1), (55, 1), (57, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1)]\n",
            "explain briefly about word2vec\n",
            "[(32, 1), (66, 1), (67, 1), (68, 1)]\n",
            "\n",
            "\n",
            " what are the applications of nlp \n",
            " [(6, 1), (8, 1), (12, 1), (14, 1), (27, 1), (42, 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYyXCA1wgDGS",
        "outputId": "ca3272d0-cceb-49df-f045-a75275381d30"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity;\n",
        "def retriveAndPrintFAQAnswer(question_embedding,sentence_embeddings,FAQdf,sentences):\n",
        "    max_sin=-1;\n",
        "    index_sin=-1;\n",
        "    for index,faq_embeddings in enumerate(sentence_embeddings):\n",
        "      #print(cosine_similarity(faq_embeddings,question_embedding))\n",
        "      sin=cosine_similarity(faq_embeddings,question_embedding)[0][0];\n",
        "      #print(\"SIN: \", sin)\n",
        "      print(index, sin, sentences[index])\n",
        "      if sin>max_sin:\n",
        "          max_sin=sin;\n",
        "          index_sin=index;\n",
        "      \n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Question: \",question)\n",
        "    print(\"\\n\");\n",
        "    print(\"Retrived: \",FAQdf.iloc[index_sin,1])\n",
        "    print(FAQdf.iloc[index_sin,2])\n",
        "\n",
        "retriveAndPrintFAQAnswer(question_embedding,bow_corpus,df,sentences);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.1643989873053573 what do you understand by natural language processing\n",
            "1 1.0 what are stop words\n",
            "2 0.9557790087219501 list any two reallife applications of natural language processing\n",
            "3 1.0 what is tfidf\n",
            "4 1.0 what is syntactic analysis\n",
            "5 1.0 what is semantic analysis\n",
            "6 1.0 what is nltk\n",
            "7 0.9928414716338373 how to tokenize a sentence using the nltk package\n",
            "8 0.8137334712067349 explain how we can do parsing\n",
            "9 0.9910476003087769 explain stemming\n",
            "10 1.0 what is pragmatic analysis\n",
            "11 1.0 what is pragmatic ambiguity\n",
            "12 1.0 what are unigrams bigrams trigrams and ngrams in nlp\n",
            "13 1.0 what is feature extraction in nlp\n",
            "14 1.0 what is partsofspeech tagging\n",
            "15 0.9910476003087769 explain named entity recognition\n",
            "16 0.9978569490503114 in nlp the process of removing words like and is a an the from a sentence is called as\n",
            "17 0.9997296931968458 tfidf helps you to establish\n",
            "18 0.9956001436530537 in nlp the process of identifying people an organization from a given sentence paragraph is called\n",
            "19 0.9910476003087769 explain briefly about word2vec\n",
            "\n",
            "\n",
            "Question:  what are the applications of nlp\n",
            "\n",
            "\n",
            "Retrived:  What are stop words?\n",
            "Stop words are said to be useless data for a search engine. Words such as articles, prepositions, etc. are considered as stop words. There are stop words such as was, were, is, am, the, a, an, how, why, and many more. In Natural Language Processing, we eliminate the stop words to understand and analyze the meaning of a sentence. The removal of stop words is one of the most important tasks for search engines. Engineers design the algorithms of search engines in such a way that they ignore the use of stop words. This helps show the relevant search result for a query.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu2uidLZkw3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f68e6b-3d45-4e4f-c7aa-a07102fa3353"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "glove_model=None;\n",
        "try:\n",
        "    glove_model = gensim.models.KeyedVectors.load(\"./glovemodel.mod\")\n",
        "    print(\"Loaded glove model\")\n",
        "except:\n",
        "    glove_model = api.load('glove-twitter-25')\n",
        "    glove_model.save(\"./glovemodel.mod\")\n",
        "    print(\"Saved glove model\")\n",
        "\n",
        "v2w_model=None;\n",
        "try:\n",
        "    v2w_model = gensim.models.KeyedVectors.load(\"./w2vecmodel.mod\")\n",
        "    print(\"Loaded w2v model\")\n",
        "except:\n",
        "    v2w_model = api.load('word2vec-google-news-300')\n",
        "    v2w_model.save(\"./w2vecmodel.mod\")\n",
        "    print(\"Saved w2v model\")\n",
        "\n",
        "w2vec_embedding_size=len(v2w_model['computer']);\n",
        "glove_embedding_size=len(glove_model['computer']);\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n",
            "Saved glove model\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Saved w2v model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkptfjK60l0j"
      },
      "source": [
        "def getWordVec(word,model):\n",
        "        samp=model['computer'];\n",
        "        vec=[0]*len(samp);\n",
        "        try:\n",
        "                vec=model[word];\n",
        "        except:\n",
        "                vec=[0]*len(samp);\n",
        "        return (vec)\n",
        "\n",
        "def getPhraseEmbedding(phrase,embeddingmodel):\n",
        "\n",
        "        samp=getWordVec('computer', embeddingmodel);\n",
        "        vec=numpy.array([0]*len(samp));\n",
        "        den=0;\n",
        "        for word in phrase.split():\n",
        "          den=den+1;\n",
        "          vec=vec+numpy.array(getWordVec(word,embeddingmodel));\n",
        "        return vec.reshape(1, -1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Rh-vFQ7Hy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e2fe9a-3d14-4356-94e2-152b71908c6b"
      },
      "source": [
        "#with w2vec\n",
        "\n",
        "sent_embeddings=[];\n",
        "for sent in cleaned_sentences:\n",
        "    sent_embeddings.append(getPhraseEmbedding(sent,v2w_model));\n",
        "\n",
        "question_embedding=getPhraseEmbedding(question,v2w_model);\n",
        "\n",
        "retriveAndPrintFAQAnswer(question_embedding,sent_embeddings,df, cleaned_sentences);\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.40878282752495915 understand natural language processing\n",
            "1 0.26417283400975394 stop words\n",
            "2 0.5524535805139236 list reallife applications natural language processing\n",
            "3 0.0 tfidf\n",
            "4 0.22370505728877457 syntactic analysis\n",
            "5 0.2582587419587579 semantic analysis\n",
            "6 0.0 nltk\n",
            "7 0.1632663466133746 tokenize sentence nltk package\n",
            "8 0.2744365775588105 explain parsing\n",
            "9 0.15298253147396465 explain stemming\n",
            "10 0.2540902553814592 pragmatic analysis\n",
            "11 0.23255324518394263 pragmatic ambiguity\n",
            "12 0.0 unigrams bigrams trigrams ngrams nlp\n",
            "13 0.23620148839441313 feature extraction nlp\n",
            "14 0.1410028698368078 partsofspeech tagging\n",
            "15 0.21998634152933544 explain named entity recognition\n",
            "16 0.34671536513131596 nlp process removing words like sentence called\n",
            "17 0.19946497309473787 tfidf helps establish\n",
            "18 0.3873620549346011 nlp process identifying people organization given sentence paragraph called\n",
            "19 0.1949722949281446 explain briefly word2vec\n",
            "\n",
            "\n",
            "Question:  what are the applications of nlp\n",
            "\n",
            "\n",
            "Retrived:  List any two real-life applications of Natural Language Processing.\n",
            "Google Translate, Chatbots\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}