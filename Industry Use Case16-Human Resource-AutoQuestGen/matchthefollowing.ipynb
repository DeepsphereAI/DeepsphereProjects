{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "matchthefollowing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqLjmxfrkK9d",
        "outputId": "07833e84-31e4-423c-f841-40d4800c7a89"
      },
      "source": [
        "# Installing from https://github.com/boudinfl/pke library for Python Keyword extraction\n",
        "# We use a fixed commit as the later changes might break the code. If it was on pip we would have used exact version number.\n",
        "\n",
        "!pip install --quiet git+https://github.com/boudinfl/pke.git@dc4d5f21e0ffe64c4df93c46146d29d1c522476b\n",
        "!pip install --quiet flashtext==2.7\n",
        "!pip install --quiet transformers==2.9.0\n",
        "!pip install --quiet nltk==3.4.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▍                              | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 22.9MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 8.6MB/s \n",
            "\u001b[?25h  Building wheel for pke (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 645kB 7.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.6MB 12.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 41.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 46.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.0MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny7eJn2ax1mm",
        "outputId": "70af07ad-e010-4f01-bebf-6d3f1e0a6ad9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhfOzDrdyAXg",
        "outputId": "05933ed0-5f41-4cab-c0a4-1f932de6d484"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import itertools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import pke\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "import traceback\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n",
        "\n",
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg9N0QnEyAct",
        "outputId": "fdb6ec56-e25e-4d38-b522-db03bd21fd7b"
      },
      "source": [
        "import textwrap\n",
        "# Story source - https://byjus.com/kids-learning/moral-stories-the-lion-and-the-mouse/\n",
        "\n",
        "text = \"\"\" Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
        "\n",
        "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.\n",
        "\n",
        "A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
        "\n",
        "As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
        "\n",
        "The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good friends and lived happily in the forest. \"\"\"\n",
        "\n",
        "wrapper = textwrap.TextWrapper(width=150)\n",
        "word_list = wrapper.wrap(text=text)\n",
        "for element in word_list: \n",
        "  print(element) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Once upon a time, there lived a lion in the dense Amazon rainforest. While he was sleeping by resting his big head on his paws, a tiny little mouse\n",
            "unexpectedly crossed by and ran across the lion’s nose in haste. This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "The poor mouse begged the lion to spare her this time and she would pay him back on some other day. Hearing this, the lion was amused and wondered how\n",
            "could such a tiny creature ever help him. But he was in a good mood and in his generosity he finally let the mouse go.  A few days later, a hunter set\n",
            "a trap for the lion while the big animal was stalking for prey in the forest. Caught in the toils of a hunter’s net, the lion found it difficult to\n",
            "free himself and roared loudly in anger.  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the\n",
            "hunter’s net. The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore\n",
            "apart. Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.  The lion thanked the little mouse for\n",
            "her help and the mouse reminded him that she had finally repaid the lion for sparing her life before. Thereafter, the lion and the mouse became good\n",
            "friends and lived happily in the forest.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylt_Zo1DyAj3",
        "outputId": "cde4f129-8f89-4fdc-cdd9-54e62a2a5186"
      },
      "source": [
        "def get_keywords(text):\n",
        "    out=[]\n",
        "    try:\n",
        "        # extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor = pke.unsupervised.YAKE()\n",
        "        extractor.load_document(input=text)\n",
        "        # pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "        pos ={'NOUN'}\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        extractor.candidate_selection(n=1,pos=pos, stoplist=stoplist)\n",
        "\n",
        "        extractor.candidate_weighting(window=3,\n",
        "                                      stoplist=stoplist,\n",
        "                                      use_stems=False)\n",
        "\n",
        "        keyphrases = extractor.get_n_best(n=30)\n",
        "        \n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_keywords(text)[:8]\n",
        "print (\"keywords: \",keywords)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keywords:  ['lion', 'mouse', 'amazon', 'net', 'hunter', 'tiny', 'free', 'big']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aVY4R1hyAob",
        "outputId": "12325174-af15-4d59-ff67-62c2f391575b"
      },
      "source": [
        "sentences = tokenize_sentences(text)\n",
        "print (sentences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Once upon a time, there lived a lion in the dense Amazon rainforest.', 'While he was sleeping by resting his big head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.', 'This woke up the lion and he laid his huge paw angrily on the tiny mouse to kill her.', 'The poor mouse begged the lion to spare her this time and she would pay him back on some other day.', 'Hearing this, the lion was amused and wondered how could such a tiny creature ever help him.', 'But he was in a good mood and in his generosity he finally let the mouse go.', 'A few days later, a hunter set a trap for the lion while the big animal was stalking for prey in the forest.', 'Caught in the toils of a hunter’s net, the lion found it difficult to free himself and roared loudly in anger.', 'As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s net.', 'The little creature quickly ran towards the lion’s trap that bound him and she gnawed the net with her sharp teeth until the net tore apart.', 'Slowly she made a big hole in the net and soon the lion was able to free himself from the hunter’s trap.', 'The lion thanked the little mouse for her help and the mouse reminded him that she had finally repaid the lion for sparing her life before.', 'Thereafter, the lion and the mouse became good friends and lived happily in the forest.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npCQw_DZyAw_",
        "outputId": "79cecfb5-cbc5-4f5f-cc7f-7830fb97b719"
      },
      "source": [
        "from pprint import pprint\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=False)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(keywords, sentences)\n",
        "pprint (keyword_sentence_mapping)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'amazon': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "            'rainforest.'],\n",
            " 'big': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'A few days later, a hunter set a trap for the lion while the big '\n",
            "         'animal was stalking for prey in the forest.',\n",
            "         'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "         'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "         'in haste.'],\n",
            " 'free': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.'],\n",
            " 'hunter': ['Slowly she made a big hole in the net and soon the lion was able '\n",
            "            'to free himself from the hunter’s trap.',\n",
            "            'A few days later, a hunter set a trap for the lion while the big '\n",
            "            'animal was stalking for prey in the forest.',\n",
            "            'Caught in the toils of a hunter’s net, the lion found it '\n",
            "            'difficult to free himself and roared loudly in anger.',\n",
            "            'As the mouse was passing by, she heard the roar and found the '\n",
            "            'lion struggling hard to free himself from the hunter’s net.'],\n",
            " 'lion': ['Once upon a time, there lived a lion in the dense Amazon '\n",
            "          'rainforest.',\n",
            "          'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Thereafter, the lion and the mouse became good friends and lived '\n",
            "          'happily in the forest.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'The poor mouse begged the lion to spare her this time and she would '\n",
            "          'pay him back on some other day.',\n",
            "          'Slowly she made a big hole in the net and soon the lion was able to '\n",
            "          'free himself from the hunter’s trap.',\n",
            "          'A few days later, a hunter set a trap for the lion while the big '\n",
            "          'animal was stalking for prey in the forest.',\n",
            "          'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "          'to free himself and roared loudly in anger.',\n",
            "          'As the mouse was passing by, she heard the roar and found the lion '\n",
            "          'struggling hard to free himself from the hunter’s net.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The lion thanked the little mouse for her help and the mouse '\n",
            "          'reminded him that she had finally repaid the lion for sparing her '\n",
            "          'life before.',\n",
            "          'The little creature quickly ran towards the lion’s trap that bound '\n",
            "          'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "          'apart.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.'],\n",
            " 'mouse': ['But he was in a good mood and in his generosity he finally let the '\n",
            "           'mouse go.',\n",
            "           'This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "           'mouse to kill her.',\n",
            "           'Thereafter, the lion and the mouse became good friends and lived '\n",
            "           'happily in the forest.',\n",
            "           'The poor mouse begged the lion to spare her this time and she '\n",
            "           'would pay him back on some other day.',\n",
            "           'As the mouse was passing by, she heard the roar and found the lion '\n",
            "           'struggling hard to free himself from the hunter’s net.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'The lion thanked the little mouse for her help and the mouse '\n",
            "           'reminded him that she had finally repaid the lion for sparing her '\n",
            "           'life before.',\n",
            "           'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "           'little mouse unexpectedly crossed by and ran across the lion’s '\n",
            "           'nose in haste.'],\n",
            " 'net': ['Slowly she made a big hole in the net and soon the lion was able to '\n",
            "         'free himself from the hunter’s trap.',\n",
            "         'Caught in the toils of a hunter’s net, the lion found it difficult '\n",
            "         'to free himself and roared loudly in anger.',\n",
            "         'As the mouse was passing by, she heard the roar and found the lion '\n",
            "         'struggling hard to free himself from the hunter’s net.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.',\n",
            "         'The little creature quickly ran towards the lion’s trap that bound '\n",
            "         'him and she gnawed the net with her sharp teeth until the net tore '\n",
            "         'apart.'],\n",
            " 'tiny': ['This woke up the lion and he laid his huge paw angrily on the tiny '\n",
            "          'mouse to kill her.',\n",
            "          'Hearing this, the lion was amused and wondered how could such a '\n",
            "          'tiny creature ever help him.',\n",
            "          'While he was sleeping by resting his big head on his paws, a tiny '\n",
            "          'little mouse unexpectedly crossed by and ran across the lion’s nose '\n",
            "          'in haste.']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7xi9a1FyA3Z",
        "outputId": "3038eb1c-cdef-490a-abf2-b281dec51d61"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "bert_wsd_pytorch = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6.zip\"\n",
        "extract_directory = \"/content/gdrive/My Drive\"\n",
        "\n",
        "extracted_folder = bert_wsd_pytorch.replace(\".zip\",\"\")\n",
        "\n",
        "#  If unzipped folder exists don't unzip again.\n",
        "if not os.path.isdir(extracted_folder):\n",
        "  with zipfile.ZipFile(bert_wsd_pytorch, 'r') as zip_ref:\n",
        "      zip_ref.extractall(extract_directory)\n",
        "else:\n",
        "  print (extracted_folder,\" is extracted already\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6  is extracted already\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwq777I_y1TE",
        "outputId": "17187ae1-0362-4ce5-f9a3-0964ba030a8b"
      },
      "source": [
        "import torch\n",
        "import math\n",
        "from transformers import BertModel, BertConfig, BertPreTrainedModel, BertTokenizer\n",
        "\n",
        "class BertWSD(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "        self.ranking_linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    \n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_dir = \"/content/gdrive/My Drive/bert_base-augmented-batch_size=128-lr=2e-5-max_gloss=6\"\n",
        "\n",
        "\n",
        "model = BertWSD.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_dir)\n",
        "# add new special token\n",
        "if '[TGT]' not in tokenizer.additional_special_tokens:\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': ['[TGT]']})\n",
        "    assert '[TGT]' in tokenizer.additional_special_tokens\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    \n",
        "model.to(DEVICE)\n",
        "model.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertWSD(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30523, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (ranking_linear): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlzaE0_1y6kq",
        "outputId": "2f70cac2-3d32-482d-9435-836f0e74a86f"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import namedtuple\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "from tabulate import tabulate\n",
        "from torch.nn.functional import softmax\n",
        "from tqdm import tqdm\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "GlossSelectionRecord = namedtuple(\"GlossSelectionRecord\", [\"guid\", \"sentence\", \"sense_keys\", \"glosses\", \"targets\"])\n",
        "BertInput = namedtuple(\"BertInput\", [\"input_ids\", \"input_mask\", \"segment_ids\", \"label_id\"])\n",
        "\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "def _create_features_from_records(records, max_seq_length, tokenizer, cls_token_at_end=False, pad_on_left=False,\n",
        "                                  cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
        "                                  sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
        "                                  cls_token_segment_id=1, pad_token_segment_id=0,\n",
        "                                  mask_padding_with_zero=True, disable_progress_bar=False):\n",
        "    \"\"\" Convert records to list of features. Each feature is a list of sub-features where the first element is\n",
        "        always the feature created from context-gloss pair while the rest of the elements are features created from\n",
        "        context-example pairs (if available)\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "    for record in tqdm(records, disable=disable_progress_bar):\n",
        "        tokens_a = tokenizer.tokenize(record.sentence)\n",
        "\n",
        "        sequences = [(gloss, 1 if i in record.targets else 0) for i, gloss in enumerate(record.glosses)]\n",
        "\n",
        "        pairs = []\n",
        "        for seq, label in sequences:\n",
        "            tokens_b = tokenizer.tokenize(seq)\n",
        "\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "\n",
        "            # The convention in BERT is:\n",
        "            # (a) For sequence pairs:\n",
        "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "            #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "            #\n",
        "            # Where \"type_ids\" are used to indicate whether this is the first\n",
        "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "            # embedding vector (and position vector). This is not *strictly* necessary\n",
        "            # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "            # it easier for the model to learn the concept of sequences.\n",
        "            #\n",
        "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "            # the entire model is fine-tuned.\n",
        "            tokens = tokens_a + [sep_token]\n",
        "            segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "            tokens += tokens_b + [sep_token]\n",
        "            segment_ids += [sequence_b_segment_id] * (len(tokens_b) + 1)\n",
        "\n",
        "            if cls_token_at_end:\n",
        "                tokens = tokens + [cls_token]\n",
        "                segment_ids = segment_ids + [cls_token_segment_id]\n",
        "            else:\n",
        "                tokens = [cls_token] + tokens\n",
        "                segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "            # tokens are attended to.\n",
        "            input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "            # Zero-pad up to the sequence length.\n",
        "            padding_length = max_seq_length - len(input_ids)\n",
        "            if pad_on_left:\n",
        "                input_ids = ([pad_token] * padding_length) + input_ids\n",
        "                input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "                segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            else:\n",
        "                input_ids = input_ids + ([pad_token] * padding_length)\n",
        "                input_mask = input_mask + ([0 if mask_padding_with_zero else 1] * padding_length)\n",
        "                segment_ids = segment_ids + ([pad_token_segment_id] * padding_length)\n",
        "\n",
        "            assert len(input_ids) == max_seq_length\n",
        "            assert len(input_mask) == max_seq_length\n",
        "            assert len(segment_ids) == max_seq_length\n",
        "\n",
        "            pairs.append(\n",
        "                BertInput(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_id=label)\n",
        "            )\n",
        "\n",
        "        features.append(pairs)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djmmKC9rzBnY",
        "outputId": "a316f756-99eb-4e02-f6fb-097638991cf8"
      },
      "source": [
        "from pprint import pprint\n",
        "sentence = \"Mark's favourite game is **Cricket**.\"\n",
        "\n",
        "sentence_for_bert = sentence.replace(\"**\",\" [TGT] \")\n",
        "sentence_for_bert = \" \".join(sentence_for_bert.split())\n",
        "\n",
        "print (sentence_for_bert)\n",
        "\n",
        "re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sentence_for_bert)\n",
        "if re_result is None:\n",
        "    print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "ambiguous_word = re_result.group(1).strip()\n",
        "\n",
        "print (\"Word: \",ambiguous_word)\n",
        "\n",
        "\n",
        "results = dict()\n",
        "\n",
        "# wn_pos = wn.NOUN\n",
        "# for i, synset in enumerate(set(wn.synsets(ambiguous_word, pos=wn_pos))):\n",
        "for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "    results[synset] =  synset.definition()\n",
        "\n",
        "pprint (results)\n",
        "\n",
        "sense_keys=[]\n",
        "definitions=[]\n",
        "for sense_key, definition in results.items():\n",
        "    sense_keys.append(sense_key)\n",
        "    definitions.append(definition)\n",
        "\n",
        "\n",
        "print (sense_keys)\n",
        "print (definitions)\n",
        "\n",
        "\n",
        "record = GlossSelectionRecord(\"test\", sentence_for_bert, sense_keys, definitions, [-1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mark's favourite game is [TGT] Cricket [TGT] .\n",
            "Word:  Cricket\n",
            "{Synset('cricket.n.01'): 'leaping insect; male makes chirping noises by '\n",
            "                         'rubbing the forewings together',\n",
            " Synset('cricket.n.02'): 'a game played with a ball and bat by two teams of 11 '\n",
            "                         'players; teams take turns trying to score runs',\n",
            " Synset('cricket.v.01'): 'play cricket'}\n",
            "[Synset('cricket.v.01'), Synset('cricket.n.02'), Synset('cricket.n.01')]\n",
            "['play cricket', 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', 'leaping insect; male makes chirping noises by rubbing the forewings together']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO978xU51kZW",
        "outputId": "b6bdb325-2047-4bc3-8210-073b64276d29"
      },
      "source": [
        "features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                          cls_token=tokenizer.cls_token,\n",
        "                                          sep_token=tokenizer.sep_token,\n",
        "                                          cls_token_segment_id=1,\n",
        "                                          pad_token_segment_id=0,\n",
        "                                          disable_progress_bar=True)[0]\n",
        "\n",
        "print (len(features))\n",
        "\n",
        "for ftr in features:\n",
        "  print (tokenizer.convert_ids_to_tokens(ftr.input_ids))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'play', 'cricket', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'a', 'game', 'played', 'with', 'a', 'ball', 'and', 'bat', 'by', 'two', 'teams', 'of', '11', 'players', ';', 'teams', 'take', 'turns', 'trying', 'to', 'score', 'runs', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['[CLS]', 'mark', \"'\", 's', 'favourite', 'game', 'is', '[UNK]', 'cricket', '[UNK]', '.', '[SEP]', 'leaping', 'insect', ';', 'male', 'makes', 'chi', '##rp', '##ing', 'noises', 'by', 'rubbing', 'the', 'forewings', 'together', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo9sShzp1keB",
        "outputId": "ca17f391-33c6-4e42-937d-5f39b82643ac"
      },
      "source": [
        "with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "print (\"\\n\")\n",
        "for pred in preds:\n",
        "  print (pred)\n",
        "sense = preds[0][0]\n",
        "meaning = preds[0][1]\n",
        "\n",
        "print (\"\\nMost appropriate sense: \",sense)\n",
        "print (\"Most appropriate meaning: \",meaning)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "(Synset('cricket.n.02'), 'a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs', tensor(0.6093, dtype=torch.float64))\n",
            "(Synset('cricket.v.01'), 'play cricket', tensor(0.3907, dtype=torch.float64))\n",
            "(Synset('cricket.n.01'), 'leaping insect; male makes chirping noises by rubbing the forewings together', tensor(9.1672e-06, dtype=torch.float64))\n",
            "\n",
            "Most appropriate sense:  Synset('cricket.n.02')\n",
            "Most appropriate meaning:  a game played with a ball and bat by two teams of 11 players; teams take turns trying to score runs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3t6ccRv1kiJ"
      },
      "source": [
        "def get_sense(sent):\n",
        "  re_result = re.search(r\"\\[TGT\\](.*)\\[TGT\\]\", sent)\n",
        "  if re_result is None:\n",
        "      print(\"\\nIncorrect input format. Please try again.\")\n",
        "\n",
        "  ambiguous_word = re_result.group(1).strip()\n",
        "  results = dict()\n",
        "\n",
        "  for i, synset in enumerate(set(wn.synsets(ambiguous_word))):\n",
        "      results[synset] =  synset.definition()\n",
        "\n",
        "  if len(results) ==0:\n",
        "    return None\n",
        "\n",
        "  sense_keys=[]\n",
        "  definitions=[]\n",
        "  for sense_key, definition in results.items():\n",
        "      sense_keys.append(sense_key)\n",
        "      definitions.append(definition)\n",
        "\n",
        "  record = GlossSelectionRecord(\"test\", sent, sense_keys, definitions, [-1])\n",
        "\n",
        "  features = _create_features_from_records([record], MAX_SEQ_LENGTH, tokenizer,\n",
        "                                            cls_token=tokenizer.cls_token,\n",
        "                                            sep_token=tokenizer.sep_token,\n",
        "                                            cls_token_segment_id=1,\n",
        "                                            pad_token_segment_id=0,\n",
        "                                            disable_progress_bar=True)[0]\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = torch.zeros(len(definitions), dtype=torch.double).to(DEVICE)\n",
        "      for i, bert_input in list(enumerate(features)):\n",
        "          logits[i] = model.ranking_linear(\n",
        "              model.bert(\n",
        "                  input_ids=torch.tensor(bert_input.input_ids, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  attention_mask=torch.tensor(bert_input.input_mask, dtype=torch.long).unsqueeze(0).to(DEVICE),\n",
        "                  token_type_ids=torch.tensor(bert_input.segment_ids, dtype=torch.long).unsqueeze(0).to(DEVICE)\n",
        "              )[1]\n",
        "          )\n",
        "      scores = softmax(logits, dim=0)\n",
        "\n",
        "      preds = (sorted(zip(sense_keys, definitions, scores), key=lambda x: x[-1], reverse=True))\n",
        "\n",
        "  sense = preds[0][0]\n",
        "  meaning = preds[0][1]\n",
        "  return sense\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTxeQKv41kmX",
        "outputId": "3bf6e03f-ac3b-4de9-aa12-e3fcd1c96d2f"
      },
      "source": [
        "import statistics \n",
        "from statistics import mode \n",
        "import re\n",
        "\n",
        "def get_synsets_for_word (word):\n",
        "  return set(wn.synsets(word))\n",
        "  \n",
        "keyword_best_sense = {}\n",
        "\n",
        "for keyword in  keyword_sentence_mapping:\n",
        "  print (\"\\n\\n\")\n",
        "  print(\"Original word: \",keyword)\n",
        "  try:\n",
        "    identified_synsets=get_synsets_for_word(keyword)\n",
        "  except:\n",
        "    continue\n",
        "  for synset in identified_synsets:\n",
        "    print (synset,\"   \",synset.definition())\n",
        "  top_3_sentences = keyword_sentence_mapping[keyword][:3]\n",
        "  best_senses=[]\n",
        "  for sent in top_3_sentences:\n",
        "    insensitive_keyword = re.compile(re.escape(keyword), re.IGNORECASE)\n",
        "    modified_sentence = insensitive_keyword.sub(\" [TGT] \"+keyword+\" [TGT] \", sent,count=1)\n",
        "    modified_sentence = \" \".join(modified_sentence.split())\n",
        "    print (\"modified sentence \",modified_sentence)\n",
        "    best_sense = get_sense(modified_sentence)\n",
        "    best_senses.append(best_sense)\n",
        "  best_sense = mode(best_senses)\n",
        "  print (\"Best sense: \",best_sense)\n",
        "  defn = best_sense.definition()\n",
        "  print (defn)\n",
        "  keyword_best_sense [keyword] = defn"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Original word:  lion\n",
            "Synset('lion.n.02')     a celebrity who is lionized (much sought after)\n",
            "Synset('leo.n.03')     the fifth sign of the zodiac; the sun is in this sign from about July 23 to August 22\n",
            "Synset('leo.n.01')     (astrology) a person who is born while the sun is in Leo\n",
            "Synset('lion.n.01')     large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "modified sentence  Once upon a time, there lived a [TGT] lion [TGT] in the dense Amazon rainforest.\n",
            "modified sentence  This woke up the [TGT] lion [TGT] and he laid his huge paw angrily on the tiny mouse to kill her.\n",
            "modified sentence  Thereafter, the [TGT] lion [TGT] and the mouse became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('lion.n.01')\n",
            "large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male\n",
            "\n",
            "\n",
            "\n",
            "Original word:  mouse\n",
            "Synset('mouse.v.02')     manipulate the mouse of a computer\n",
            "Synset('mouse.n.04')     a hand-operated electronic device that controls the coordinates of a cursor on your computer screen as you move it around on a pad; on the bottom of the device is a ball that rolls on the surface of the pad\n",
            "Synset('shiner.n.01')     a swollen bruise caused by a blow to the eye\n",
            "Synset('sneak.v.01')     to go stealthily or furtively\n",
            "Synset('mouse.n.03')     person who is quiet or timid\n",
            "Synset('mouse.n.01')     any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "modified sentence  But he was in a good mood and in his generosity he finally let the [TGT] mouse [TGT] go.\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the tiny [TGT] mouse [TGT] to kill her.\n",
            "modified sentence  Thereafter, the lion and the [TGT] mouse [TGT] became good friends and lived happily in the forest.\n",
            "Best sense:  Synset('mouse.n.01')\n",
            "any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails\n",
            "\n",
            "\n",
            "\n",
            "Original word:  amazon\n",
            "Synset('amazon.n.02')     (Greek mythology) one of a nation of women warriors of Scythia (who burned off the right breast in order to use a bow and arrow more effectively)\n",
            "Synset('amazon.n.04')     mainly green tropical American parrots\n",
            "Synset('amazon.n.03')     a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "Synset('amazon.n.01')     a large strong and aggressive woman\n",
            "modified sentence  Once upon a time, there lived a lion in the dense [TGT] amazon [TGT] rainforest.\n",
            "Best sense:  Synset('amazon.n.03')\n",
            "a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\n",
            "\n",
            "\n",
            "\n",
            "Original word:  net\n",
            "Synset('net.n.05')     game equipment consisting of a strip of netting dividing the playing area in tennis or badminton\n",
            "Synset('net.n.04')     a goal lined with netting (as in soccer or hockey)\n",
            "Synset('net_income.n.01')     the excess of revenues over outlays in a given period of time (including depreciation and other non-cash expenses)\n",
            "Synset('final.s.02')     conclusive in a process or progression\n",
            "Synset('internet.n.01')     a computer network consisting of a worldwide network of computer networks that use the TCP/IP network protocols to facilitate data transmission and exchange\n",
            "Synset('net.n.06')     an open fabric of string or rope or wire woven together at regular intervals\n",
            "Synset('net.a.01')     remaining after all deductions\n",
            "Synset('net.n.02')     a trap made of netting to catch fish or birds or insects\n",
            "Synset('net.v.02')     yield as a net profit\n",
            "Synset('web.v.01')     construct or form a web, as if by weaving\n",
            "Synset('net.v.04')     catch with a net\n",
            "Synset('net.v.01')     make as a net profit\n",
            "modified sentence  Slowly she made a big hole in the [TGT] net [TGT] and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s [TGT] net [TGT] , the lion found it difficult to free himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to free himself from the hunter’s [TGT] net [TGT] .\n",
            "Best sense:  Synset('net.n.02')\n",
            "a trap made of netting to catch fish or birds or insects\n",
            "\n",
            "\n",
            "\n",
            "Original word:  hunter\n",
            "Synset('hunter.n.02')     a person who searches for something\n",
            "Synset('hunter.n.01')     someone who hunts game\n",
            "Synset('hunter.n.04')     a watch with a hinged metal lid to protect the crystal\n",
            "Synset('orion.n.02')     a constellation on the equator to the east of Taurus; contains Betelgeuse and Rigel\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to free himself from the [TGT] hunter [TGT] ’s trap.\n",
            "modified sentence  A few days later, a [TGT] hunter [TGT] set a trap for the lion while the big animal was stalking for prey in the forest.\n",
            "modified sentence  Caught in the toils of a [TGT] hunter [TGT] ’s net, the lion found it difficult to free himself and roared loudly in anger.\n",
            "Best sense:  Synset('hunter.n.01')\n",
            "someone who hunts game\n",
            "\n",
            "\n",
            "\n",
            "Original word:  tiny\n",
            "Synset('bantam.s.01')     very small\n",
            "modified sentence  This woke up the lion and he laid his huge paw angrily on the [TGT] tiny [TGT] mouse to kill her.\n",
            "modified sentence  Hearing this, the lion was amused and wondered how could such a [TGT] tiny [TGT] creature ever help him.\n",
            "modified sentence  While he was sleeping by resting his big head on his paws, a [TGT] tiny [TGT] little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('bantam.s.01')\n",
            "very small\n",
            "\n",
            "\n",
            "\n",
            "Original word:  free\n",
            "Synset('dislodge.v.01')     remove or force out from a position\n",
            "Synset('loose.r.01')     without restraint\n",
            "Synset('free.v.06')     free from obligations or duties\n",
            "Synset('rid.v.01')     relieve from\n",
            "Synset('exempt.v.01')     grant relief or an exemption from a rule or requirement to\n",
            "Synset('free.s.09')     not literal\n",
            "Synset('unblock.v.03')     make (assets) available\n",
            "Synset('free.v.05')     make (information) available for publication\n",
            "Synset('detached.s.06')     not fixed in position\n",
            "Synset('free.a.02')     unconstrained or not chemically bound in a molecule or not fixed and capable of relatively unrestricted motion\n",
            "Synset('free.a.01')     able to act at will; not hampered; not under compulsion or restraint\n",
            "Synset('spare.s.03')     not taken up by scheduled activities\n",
            "Synset('barren.s.03')     completely wanting or lacking\n",
            "Synset('free.n.01')     people who are free\n",
            "Synset('absolve.v.02')     let off the hook\n",
            "Synset('complimentary.s.02')     costing nothing\n",
            "Synset('release.v.08')     part with a possession or right\n",
            "Synset('free.v.01')     grant freedom to; free from confinement\n",
            "Synset('free.a.06')     not held in servitude\n",
            "Synset('free.s.04')     not occupied or in use\n",
            "Synset('free.v.07')     free or remove obstruction from\n",
            "Synset('release.v.09')     release (gas or energy) as a result of a chemical reaction or physical decomposition\n",
            "modified sentence  Slowly she made a big hole in the net and soon the lion was able to [TGT] free [TGT] himself from the hunter’s trap.\n",
            "modified sentence  Caught in the toils of a hunter’s net, the lion found it difficult to [TGT] free [TGT] himself and roared loudly in anger.\n",
            "modified sentence  As the mouse was passing by, she heard the roar and found the lion struggling hard to [TGT] free [TGT] himself from the hunter’s net.\n",
            "Best sense:  Synset('free.a.01')\n",
            "able to act at will; not hampered; not under compulsion or restraint\n",
            "\n",
            "\n",
            "\n",
            "Original word:  big\n",
            "Synset('big.r.03')     on a grand scale\n",
            "Synset('big.s.02')     significant\n",
            "Synset('large.a.01')     above average in size or number or quantity or magnitude or extent\n",
            "Synset('big.s.10')     marked by intense physical force\n",
            "Synset('adult.s.01')     (of animals) fully developed\n",
            "Synset('boastfully.r.01')     in a boastful manner\n",
            "Synset('big.s.04')     loud and firm\n",
            "Synset('big.s.06')     prodigious\n",
            "Synset('big.r.04')     in a major way\n",
            "Synset('big.s.13')     in an advanced stage of pregnancy\n",
            "Synset('bad.s.02')     very intense\n",
            "Synset('big.r.01')     extremely well\n",
            "Synset('big.s.05')     conspicuous in position or importance\n",
            "Synset('big.s.11')     generous and understanding and tolerant\n",
            "Synset('big.s.08')     feeling self-importance\n",
            "Synset('big.s.12')     given or giving freely\n",
            "Synset('boastful.s.01')     exhibiting self-importance\n",
            "modified sentence  Slowly she made a [TGT] big [TGT] hole in the net and soon the lion was able to free himself from the hunter’s trap.\n",
            "modified sentence  A few days later, a hunter set a trap for the lion while the [TGT] big [TGT] animal was stalking for prey in the forest.\n",
            "modified sentence  While he was sleeping by resting his [TGT] big [TGT] head on his paws, a tiny little mouse unexpectedly crossed by and ran across the lion’s nose in haste.\n",
            "Best sense:  Synset('large.a.01')\n",
            "above average in size or number or quantity or magnitude or extent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub6XJ1AW1krQ",
        "outputId": "2629626e-175e-458c-b24d-7d6a8bffe85e"
      },
      "source": [
        "pprint (keyword_best_sense)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'amazon': 'a major South American river; arises in the Andes and flows '\n",
            "           \"eastward into the South Atlantic; the world's 2nd longest river \"\n",
            "           '(4000 miles)',\n",
            " 'big': 'above average in size or number or quantity or magnitude or extent',\n",
            " 'free': 'able to act at will; not hampered; not under compulsion or restraint',\n",
            " 'hunter': 'someone who hunts game',\n",
            " 'lion': 'large gregarious predatory feline of Africa and India having a tawny '\n",
            "         'coat with a shaggy mane in the male',\n",
            " 'mouse': 'any of numerous small rodents typically resembling diminutive rats '\n",
            "          'having pointed snouts and small ears on elongated bodies with '\n",
            "          'slender usually hairless tails',\n",
            " 'net': 'a trap made of netting to catch fish or birds or insects',\n",
            " 'tiny': 'very small'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0wXk8w1-r9",
        "outputId": "a76ba5bb-d373-4a6c-de6e-4dfbb3cb62df"
      },
      "source": [
        "import random \n",
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "all_keywords= list(keyword_best_sense.keys())\n",
        "all_definitions = list(keyword_best_sense.values())\n",
        "random.shuffle(all_keywords)\n",
        "random.shuffle(all_definitions)\n",
        "print (all_keywords)\n",
        "print (all_definitions)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['free', 'amazon', 'mouse', 'lion', 'tiny', 'hunter', 'big', 'net']\n",
            "['a trap made of netting to catch fish or birds or insects', 'someone who hunts game', \"a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)\", 'large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male', 'able to act at will; not hampered; not under compulsion or restraint', 'above average in size or number or quantity or magnitude or extent', 'any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails', 'very small']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "OOxQOXvd1-z6",
        "outputId": "f4d6e54e-375f-4cb7-b920-3cd265099d94"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "x.field_names=['Word', \"Definition\"]\n",
        "for word,defn in zip(all_keywords,all_definitions):\n",
        "  x.add_row([word,defn])\n",
        "\n",
        "printmd(\"**Match the following words to their correct meanings.**\")\n",
        "# print (\"\\n\")\n",
        "print (x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "**Match the following words to their correct meanings.**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  Word  |                                                                            Definition                                                                           |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|  free  |                                                     a trap made of netting to catch fish or birds or insects                                                    |\n",
            "| amazon |                                                                      someone who hunts game                                                                     |\n",
            "| mouse  |             a major South American river; arises in the Andes and flows eastward into the South Atlantic; the world's 2nd longest river (4000 miles)            |\n",
            "|  lion  |                             large gregarious predatory feline of Africa and India having a tawny coat with a shaggy mane in the male                            |\n",
            "|  tiny  |                                               able to act at will; not hampered; not under compulsion or restraint                                              |\n",
            "| hunter |                                                above average in size or number or quantity or magnitude or extent                                               |\n",
            "|  big   | any of numerous small rodents typically resembling diminutive rats having pointed snouts and small ears on elongated bodies with slender usually hairless tails |\n",
            "|  net   |                                                                            very small                                                                           |\n",
            "+--------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qog1Ojzh1-5-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPKhRwfb1_A8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAYTKeBE1_HH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBRX9qky1_NG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsPvqOxq1_Sa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}