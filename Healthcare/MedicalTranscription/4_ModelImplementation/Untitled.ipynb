{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "valued-replica",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CliNER'...\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 3900 (delta 1), reused 0 (delta 0), pack-reused 3891\u001b[K\n",
      "Receiving objects: 100% (3900/3900), 81.40 MiB | 33.58 MiB/s, done.\n",
      "Resolving deltas: 100% (2560/2560), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/text-machine-lab/CliNER.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "diverse-career",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/DeepsphereProjects/Healthcare/MedicalTranscription/4_ModelImplementation/CliNER\n"
     ]
    }
   ],
   "source": [
    "%cd CliNER/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-battlefield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 9.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-crfsuite\n",
      "  Downloading python_crfsuite-0.9.7-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
      "\u001b[K     |████████████████████████████████| 743 kB 34.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (1.6.0)\n",
      "Collecting marisa-trie\n",
      "  Downloading marisa-trie-0.7.5.tar.gz (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 40.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting repoze.lru\n",
      "  Downloading repoze.lru-0.7-py3-none-any.whl (10 kB)\n",
      "Collecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.1 MB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk->-r requirements.txt (line 1)) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->-r requirements.txt (line 1)) (4.56.0)\n",
      "Building wheels for collected packages: marisa-trie, nltk\n",
      "  Building wheel for marisa-trie (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp37-cp37m-linux_x86_64.whl size=1088489 sha256=175af94a524155e971058949d6493820a61d74aa1237f84a52b892f34e15e99d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/01/ac/46/c838fd1aee138a8fd92ae30b04020995182eb4d99dec1e12ea\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434674 sha256=48c4fddb2e8b8a7a71e9e680e0fb269af01605fd8442bf84f80c87c8b31bbd49\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
      "Successfully built marisa-trie nltk\n",
      "Installing collected packages: scikit-learn, repoze.lru, python-crfsuite, nltk, marisa-trie\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.1\n",
      "    Uninstalling scikit-learn-0.24.1:\n",
      "      Successfully uninstalled scikit-learn-0.24.1\n",
      "Successfully installed marisa-trie-0.7.5 nltk-3.5 python-crfsuite-0.9.7 repoze.lru-0.7 scikit-learn-0.22.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extreme-spectrum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-15 13:50:31--  http://text-machine.cs.uml.edu/cliner/models/silver.crf\n",
      "Resolving text-machine.cs.uml.edu (text-machine.cs.uml.edu)... 146.189.182.142\n",
      "Connecting to text-machine.cs.uml.edu (text-machine.cs.uml.edu)|146.189.182.142|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 129956975 (124M)\n",
      "Saving to: ‘silver.crf’\n",
      "\n",
      "silver.crf          100%[===================>] 123.94M  37.1MB/s    in 3.9s    \n",
      "\n",
      "2021-02-15 13:50:35 (31.7 MB/s) - ‘silver.crf’ saved [129956975/129956975]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget http://text-machine.cs.uml.edu/cliner/models/silver.crf\n",
    "\n",
    "! mv silver.crf models/silver.crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjustable-trout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.dict_vectorizer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction. Anything that cannot be imported from sklearn.feature_extraction is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.19.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "------------------------------\n",
      "\n",
      "\t1 of 1\n",
      "\tdata/examples/hospital111.txt\n",
      "\n",
      "\tvectorizing words all\n",
      "\tpredicting  labels all\n",
      "\n",
      "\n",
      "writing to: data/predictions/hospital111.con\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python cliner predict --txt data/examples/hospital111.txt --out data/predictions --model models/silver.crf --format i2b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-montgomery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
