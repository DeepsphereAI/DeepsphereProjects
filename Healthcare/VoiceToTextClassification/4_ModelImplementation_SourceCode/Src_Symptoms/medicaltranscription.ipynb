{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assisted-timer",
   "metadata": {},
   "source": [
    "/*************************************************************************************************************************\n",
    "                                                     ##Disclaimer##\n",
    "    \n",
    "-> We are providing this code block strictly for learning and researching, this is not a production ready code. \n",
    "-> We have no liability on this particular code under any circumstances; users should use this code on their own risk. \n",
    "\n",
    "-> All software, hardware and othr products that are referenced in these materials belong to the respective vendor who developed or who owns this product.\n",
    "\n",
    "/*************************************************************************************************************************\n",
    "                                                  @DeepSphere.AI ,Inc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-earthquake",
   "metadata": {},
   "source": [
    "# Step 0: downloading data from storage bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "# Initialise a client\n",
    "storage_client = storage.Client(\"medicaltranscript \")\n",
    "# Create a bucket object for our bucket\n",
    "bucket = storage_client.get_bucket('medicaltranscript')\n",
    "# Create a blob object from the filepath\n",
    "blob = bucket.blob(\"deepspeech_file.zip\")\n",
    "# Download the file to a destination\n",
    "blob.download_to_filename('deepspeech_file.zip')\n",
    "\n",
    "!unzip deepspeech_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-decade",
   "metadata": {},
   "source": [
    "# Step 1: .YAML File Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "# Importing the yaml library\n",
    "\n",
    "import yaml\n",
    "# Importing the OS library\n",
    "\n",
    "import os\n",
    "\n",
    "vAR_yaml_file_path = '/home/jupyter/MT/Healthcare/MedicalTranscription/4_ModelImplementation/config.yaml'\n",
    "    \n",
    "with open (vAR_yaml_file_path) as vAR_file:\n",
    "    \n",
    "           config = yaml.safe_load(vAR_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "vAR_Text_Path=config.get(\"text_file\")\n",
    "vAR_Model_Path=config.get(\"model_file_path\")\n",
    "vAR_LM_Path=config.get(\"lm_file_path\")\n",
    "vAR_Symptom_Path=config.get(\"symptoms_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-telling",
   "metadata": {},
   "source": [
    "# Step 2: Importing the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepspeech import Model \n",
    "import numpy as np\n",
    "import wave\n",
    "import git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-strike",
   "metadata": {},
   "source": [
    "# Step 3: Importing DeepSpeech model for convert audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():  \n",
    "    Voice_to_text()\n",
    "    Clone_CliNER()\n",
    "    Predict_symptoms()\n",
    "    Text_Classification_and_Visualization()\n",
    "    \n",
    "def Voice_to_text():\n",
    "    vAR_beam_width=1000\n",
    "    vAR_lm_alpha=0.93 \n",
    "    vAR_lm_beta=1.18\n",
    "\n",
    "    model=Model(vAR_Model_Path)\n",
    "    model.enableExternalScorer(vAR_LM_Path)\n",
    "\n",
    "    model.setScorerAlphaBeta(vAR_lm_alpha,vAR_lm_beta)\n",
    "    model.setBeamWidth(vAR_beam_width)\n",
    "    \n",
    "# Conversion of audio data to 16khz\n",
    "    !ffmpeg -i hospital.wav -vn -ar 16000 -ac 1 hospital1.wav\n",
    "\n",
    "    def read_wav_file(filename):\n",
    "        with wave.open(filename, 'rb') as vAR_temp:       # \"rb\" mode opens the file in binary format for reading\n",
    "            rate=vAR_temp.getframerate()\n",
    "            frames=vAR_temp.getnframes()\n",
    "            buffer=vAR_temp.readframes(frames)\n",
    "        return buffer, rate\n",
    "\n",
    "    def transcribe(file):\n",
    "        buffer,rate=read_wav_file(file)\n",
    "        data16=np.frombuffer(buffer,dtype=np.int16)\n",
    "        return model.stt(data16)\n",
    "    \n",
    "# Storing the output in a .txt file    \n",
    "    f= open(vAR_Text_Path,\"w+\")\n",
    "\n",
    "    f.write(transcribe('hospital1.wav'))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-marina",
   "metadata": {},
   "source": [
    "# Step 4: Extracting Symptoms from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clone_CliNER():\n",
    "    git.Git(\"DeepsphereProjects/Healthcare/MedicalTranscription/4_ModelImplementation\").clone(\"https://github.com/text-machine-lab/CliNER.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_symptoms():\n",
    "    %cd CliNER/\n",
    "    !python cliner predict --txt DeepsphereProjects/Healthcare/MedicalTranscription/4_ModelImplementation/CliNER/data/examples/hospital111.txt --out data/predictions --model models/silver.crf --format i2b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-crystal",
   "metadata": {},
   "source": [
    "# Step 5: Text classification and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Classification_and_Visualization():\n",
    "    with open(vAR_Text_Path,'r') as file:\n",
    "        read_file = file.read()\n",
    "# Text analytics (summarized content)\n",
    "    tokenized_text=sent_tokenize(read_file)\n",
    "    tokenized_word=word_tokenize(read_file)\n",
    "\n",
    "    fdist = FreqDist(tokenized_word)\n",
    "# removing all the stop words\n",
    "    vAR_stop_words=set(stopwords.words(\"english\"))\n",
    "    filtered_sent=[]\n",
    "    for vAR_iter in tokenized_word:\n",
    "        if vAR_iter not in vAR_stop_words:\n",
    "            filtered_sent.append(vAR_iter)\n",
    "    with open(vAR_Symptom_Path, \"r\") as vAR:\n",
    "        lines = vAR.readlines()\n",
    "    Outputlist = []\n",
    "# matched symptoms from filtered tokenized words from text file\n",
    "    for vAR_val in filtered_sent:\n",
    "        with open(vAR_Symptom_Path,\"r\") as vAR:\n",
    "            lines = vAR.readlines()\n",
    "        for line in lines:\n",
    "            vAR_out = line.strip()\n",
    "            if vAR_val == vAR_out:\n",
    "                Outputlist.append(vAR_val)\n",
    "# Plotting a Line Chart                \n",
    "    plt.plot(Outputlist)\n",
    "    plt.ylabel('Symptoms')\n",
    "    plt.xlabel('numbers')\n",
    "    plt.show()\n",
    "    symptoms = list(set(Outputlist))\n",
    "    print(symptoms)\n",
    "    vAR_df = DataFrame (Outputlist,columns=['Symptoms'])\n",
    "    vAR_table=vAR_df['Symptoms'].value_counts()\n",
    "    \n",
    "# visualization using Pie chart\n",
    "    vAR_table.plot.pie(y=vAR_df.index,shadow=False, explode=None, startangle=90, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    cf.go_offline()\n",
    "    cf.set_config_file(offline=False, world_readable=True)\n",
    "# visualization using cufflinks and plotly libraries\n",
    "    vAR_df.iplot(kind='hist',bins=50,xTitle='symptoms',linecolor='black',yTitle='frequency',title='Symptoms frequency distribution')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
